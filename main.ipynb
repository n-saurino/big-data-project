{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be5532d-f960-4781-9bcd-46e9fc649520",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip\n",
    "# !pip install tqdm\n",
    "# !pip install dask\n",
    "# !pip install apache-sedona\n",
    "# !pip install shapely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1161ce3c-f44d-4315-a465-e24bb275488f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda\n",
    "# !conda install tqdm\n",
    "# !conda install dask\n",
    "#!conda install findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ce98286-fb6b-4af9-994f-689a6f13d838",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sedona.register import SedonaRegistrator  \n",
    "from sedona.utils import SedonaKryoRegistrator, KryoSerializer\n",
    "from shapely.geometry import Point\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "from haversine import haversine, Unit\n",
    "import pyspark.sql.types as types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20c7e655-046c-4da4-a507-d6c82a395dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration, worked on using python@3.10.9 \n",
    "import os\n",
    "import urllib\n",
    "import json\n",
    "from threading import Thread, Lock\n",
    "from tqdm import tqdm\n",
    "from kafka import KafkaConsumer, KafkaProducer\n",
    "import pyspark\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0745851c-98cb-468f-8422-527aa52bcb08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://workHorse:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.4.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[7]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x268952d2220>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf = pyspark.SparkConf()\\\n",
    "    .setMaster(\"local[7]\")\\\n",
    "    .set(\"spark.eventLog.enabled\", \"true\")\\\n",
    "    .set(\"spark.eventLog.dir\", \"./logs\")\\\n",
    "    .set(\"spark.eventLog.gcMetrics.youngGenerationGarbageCollectors\", \"true\")\\\n",
    "    .set(\"spark.executor.heartbeatInterval\",\"3600s\")\\\n",
    "    .set(\"spark.network.timeout\",\"3601s\")\n",
    "    # .set(\"spark.kryo.registrator\", SedonaKryoRegistrator.getName)\\\n",
    "    # .set(\"spark.kryo.registrator\", SedonaKryoRegistrator.getName)\\\n",
    "    # .set('spark.jars.packages',\n",
    "           # 'org.apache.sedona:sedona-spark-shaded-3.0_2.12:1.4.0,'\n",
    "           # 'org.datasyslab:geotools-wrapper:1.4.0-28.2')\n",
    "\n",
    "'''\n",
    "sparkSession = SparkSession. \\\n",
    "    builder. \\\n",
    "    appName('appName'). \\\n",
    "    config(\"spark.serializer\", KryoSerializer.getName). \\\n",
    "    config(\"spark.kryo.registrator\", SedonaKryoRegistrator.getName). \\\n",
    "    config('spark.jars.packages',\n",
    "           'org.apache.sedona:sedona-spark-shaded-3.0_2.12:1.4.0,'\n",
    "           'org.datasyslab:geotools-wrapper:1.4.0-28.2'). \\\n",
    "    getOrCreate()\n",
    "'''\n",
    "\n",
    "sc = pyspark.SparkContext(conf=conf)\n",
    "sc.setLogLevel('ERROR')\n",
    "spark = pyspark.sql.SparkSession(sc)\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4b68d9-800f-400e-ae44-196e39a7680d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SedonaRegistrator.registerAll(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78fd043a-320a-4e86-86a8-df4b0b177f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data folder\n",
    "data_dir = 'data'\n",
    "\n",
    "# data urls\n",
    "historic_arrest_loc = { 'url': 'https://data.cityofnewyork.us/resource/8h9b-rp9u.json?$limit=10', 'filename': 'lil_arrest.json' }\n",
    "historic_complaint_loc = { 'url': 'https://data.cityofnewyork.us/resource/qgea-i56i.json?$limit=15000000', 'filename': 'complaint.json' }\n",
    "historic_court_summons_loc = { 'url': 'https://data.cityofnewyork.us/resource/sv2w-rv3k.json?$limit=15000000', 'filename': 'summons.json' }\n",
    "traffic_speed_loc = { 'url': 'https://data.cityofnewyork.us/resource/i4gi-tjb9.json?$limit=15000000', 'filename': 'speed.json' }\n",
    "turnstile_loc = { 'url': 'https://data.ny.gov/resource/i55r-43gk.json?$limit=15000000', 'filename': 'turnstile.json' }\n",
    "#subway_loc = { 'url': 'https://data.ny.gov/resource/i9wp-a4ja.json?$limit=15000000', 'filename': 'subway.json' }\n",
    "subway_loc = { 'url': 'http://web.mta.info/developers/data/nyct/subway/Stations.csv?$limit=15000000', 'filename': 'subway.csv' }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "296b368d-abad-457e-9273-a4d58bb0164c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download flags\n",
    "downloadflag = True\n",
    "redownload = False\n",
    "\n",
    "thread_lock = Lock()\n",
    "\n",
    "# download utils\n",
    "def download_dataset_thread(loc, folder):\n",
    "    with thread_lock:\n",
    "         if ((not os.path.exists(os.path.join(folder, loc['filename']))) or redownload) and downloadflag:\n",
    "            if os.path.isfile(os.path.join(folder, loc['filename'])):\n",
    "                os.remove(os.path.join(folder, loc['filename']))\n",
    "            if not os.path.exists(folder):\n",
    "                os.makedirs(folder) \n",
    "            with tqdm(unit=\"B\", unit_scale=True, desc=loc['filename'], miniters=1) as progress_bar:\n",
    "                urllib.request.urlretrieve(loc['url'], os.path.join(folder, loc['filename']), lambda block_num, block_size, total_size: progress_bar.update(block_size))\n",
    "            progress_bar.display()\n",
    "        \n",
    "def download_dataset(loc, folder):\n",
    "    thread = Thread(target=download_dataset_thread, args=(loc, folder))\n",
    "    thread.start()\n",
    "    thread.join()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3bf5d47c-e667-4356-a238-d10729cb744b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download datasets\n",
    "for dataset in [historic_arrest_loc,\n",
    "                historic_complaint_loc,\n",
    "                historic_court_summons_loc,\n",
    "                turnstile_loc,\n",
    "                subway_loc]:\n",
    "    download_dataset(dataset, data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03187c4-9ff0-4728-8926-3bcdda56315c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframes\n",
    "arrest_rdd = spark.read.json(os.path.join(data_dir, historic_arrest_loc['filename']), multiLine=True)\n",
    "complaint_rdd = spark.read.json(os.path.join(data_dir, historic_complaint_loc['filename']), multiLine=True)\n",
    "summons_rdd = spark.read.json(os.path.join(data_dir, historic_court_summons_loc['filename']), multiLine=True)\n",
    "turnstile_rdd = spark.read.json(os.path.join(data_dir, turnstile_loc['filename']), multiLine=True)\n",
    "subway_rdd = spark.read.csv(os.path.join(data_dir, subway_loc['filename']), header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2166298f-6ea3-401b-bcbd-603cdd65b10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#subway_rdd = spark.read.json(os.path.join(data_dir, subway_loc['filename']), multiLine=True)\n",
    "subway_rdd = spark.read.csv(os.path.join(data_dir, subway_loc['filename']), header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1a412d-5a3b-45cd-a0f5-fa61a9c6c41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "arrest_rdd = spark.read.json(os.path.join(data_dir, historic_arrest_loc['filename']), multiLine=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d12d731d-0181-4fb7-a41b-6ee0121047bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "lil_arrest_rdd = spark.read.json(os.path.join(data_dir, historic_arrest_loc['filename']), multiLine=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55b29ff0-4812-4fd5-9e3d-267f51352243",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subway_DF = subway_rdd.toDF(\"ada\", \"ada_notes\", \"corner\", \"division\", \"east_west_street\", \"entrance_georeference\", \"entrance_latitude\", \"entrance_location\", \"entrance_longitude\", \"entrance_type\", \"entry\", \"exit_only\", \"free_crossover\", \"line\", \"north_south_street\", \"route1\", \"route10\", \"route11\", \"route2\", \"route3\", \"route4\", \"route5\", \"route6\", \"route7\", \"route8\", \"route9\", \"staff_hours\", \"staffing\", \"station_georeference\", \"station_latitude\", \"station_location\", \"station_longitude\", \"station_name\", \"vending\")\n",
    "subway_DF = subway_rdd.toDF(\"Station ID\", \"Complex ID\", \"GTFS Stop ID\", \"Division\", \"Line\", \"Stop Name\", \"Borough\", \"Daytime Routes\", \"Structure\", \"GTFS Latitude\", \"GTFS Longitude\", \"North Direction Label\", \"South Direction Label\", \"ADA\", \"ADA Direction Notes\", \"ADA NB\", \"ADA SB\", \"Capital Outage NB\", \"Capital Outage SB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e1fe1fa-8c11-4996-b464-d3187618b920",
   "metadata": {},
   "outputs": [],
   "source": [
    "#subway_DF = subway_DF.select(\"station_name\",\"station_latitude\", \"station_longitude\", \"station_location\", \"station_georeference\")\n",
    "subway_DF = subway_DF.select('Station ID', 'Complex ID', 'GTFS Stop ID', 'Stop Name', 'Borough', 'GTFS Latitude','GTFS Longitude')\\\n",
    "                     .filter(F.col('GTFS Latitude').isNotNull() & F.col('GTFS Longitude').isNotNull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "43b63eb5-eb6f-48d3-a646-1c50e101f9de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+------------+--------------------+-------+-------------+--------------+\n",
      "|Station ID|Complex ID|GTFS Stop ID|           Stop Name|Borough|GTFS Latitude|GTFS Longitude|\n",
      "+----------+----------+------------+--------------------+-------+-------------+--------------+\n",
      "|         1|         1|         R01|Astoria-Ditmars Blvd|      Q|    40.775036|    -73.912034|\n",
      "|         2|         2|         R03|        Astoria Blvd|      Q|    40.770258|    -73.917843|\n",
      "|         3|         3|         R04|               30 Av|      Q|    40.766779|    -73.921479|\n",
      "|         4|         4|         R05|            Broadway|      Q|     40.76182|    -73.925508|\n",
      "|         5|         5|         R06|               36 Av|      Q|    40.756804|    -73.929575|\n",
      "|         6|         6|         R08|   39 Av-Dutch Kills|      Q|    40.752882|    -73.932755|\n",
      "|         7|       613|         R11|  Lexington Av/59 St|      M|     40.76266|    -73.967258|\n",
      "|         8|         8|         R13|          5 Av/59 St|      M|    40.764811|    -73.973347|\n",
      "|         9|         9|         R14|          57 St-7 Av|      M|    40.764664|    -73.980658|\n",
      "|        10|        10|         R15|               49 St|      M|    40.759901|    -73.984139|\n",
      "|        11|       611|         R16|      Times Sq-42 St|      M|    40.754672|    -73.986754|\n",
      "|        12|       607|         R17|     34 St-Herald Sq|      M|    40.749567|     -73.98795|\n",
      "|        13|        13|         R18|               28 St|      M|    40.745494|    -73.988691|\n",
      "|        14|        14|         R19|               23 St|      M|    40.741303|    -73.989344|\n",
      "|        15|       602|         R20|      14 St-Union Sq|      M|    40.735736|    -73.990568|\n",
      "|        16|        16|         R21|            8 St-NYU|      M|    40.730328|    -73.992629|\n",
      "|        17|        17|         R22|           Prince St|      M|    40.724329|    -73.997702|\n",
      "|        18|       623|         R23|            Canal St|      M|    40.719527|    -74.001775|\n",
      "|        19|       623|         Q01|            Canal St|      M|    40.718383|     -74.00046|\n",
      "|        20|        20|         R24|           City Hall|      M|    40.713282|    -74.006978|\n",
      "+----------+----------+------------+--------------------+-------+-------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "subway_DF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e5997b50-94f7-4db6-8bdc-85898cd68bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Station ID: integer (nullable = true)\n",
      " |-- Complex ID: integer (nullable = true)\n",
      " |-- GTFS Stop ID: string (nullable = true)\n",
      " |-- Stop Name: string (nullable = true)\n",
      " |-- Borough: string (nullable = true)\n",
      " |-- GTFS Latitude: double (nullable = true)\n",
      " |-- GTFS Longitude: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "subway_DF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d8ac8544-d683-4905-8e60-c3e733e64052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "496"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subway_DF.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b94f75-2417-4ee8-8686-6e79905352a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSIDER DROPPING SUBWAY STOPS WITH DUPLICATE NAMES?\n",
    "# subway_DF.dropDuplicates(subset=[\"Stop Name\"]).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef085fa-0649-43ef-a13d-1fc7d82213ce",
   "metadata": {},
   "source": [
    "Adapting the Haversine function from Homework 2. Setting it to check distance in meters between lat/lon pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "775bd688-9fb4-405d-858b-faec2a39910a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def withinMeters(slat, slong, dlat, dlong):\n",
    "    srs = (slat, slong)\n",
    "    dst = (dlat, dlong)\n",
    "    print(type(srs[0]),type(srs[1]))\n",
    "    print(srs[0],srs[1])\n",
    "    print(type(dst[0]),type(dst[1]))\n",
    "    print(dst[0],dst[1])\n",
    "    distance = float(haversine(srs, dst,unit=Unit.METERS))\n",
    "    print(distance)\n",
    "    return bool(distance < 402)\n",
    "    \n",
    "withinMetersUdf = F.udf(withinMeters, types.BooleanType())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f00a197-ae7f-4c63-b895-76e3a7f60536",
   "metadata": {},
   "source": [
    "Tried to get the join to work on the full arrest data set but failed and have commented it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f96a13a-bfd8-4c86-b554-6ab4c91bfce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# arrest_DF = arrest_rdd.toDF(\":@computed_region_92fq_4b7q\", \":@computed_region_efsh_h5xi\", \":@computed_region_f5dn_yrer\", \":@computed_region_sbqj_enih\", \":@computed_region_yeji_bk3q\", \"age_group\", \"arrest_boro\", \"arrest_date\", \"arrest_key\", \"arrest_precinct\", \"jurisdiction_code\", \"ky_cd\", \"latitude\", \"law_cat_cd\", \"law_code\", \"lon_lat\", \"longitude\", \"ofns_desc\", \"pd_cd\", \"pd_desc\", \"perp_race\", \"perp_sex\", \"x_coord_cd\", \"y_coord_cd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bedde2e-acaf-46b0-b264-8ff9738b8ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# arrest_DF = arrest_DF.select(\"arrest_boro\",\"arrest_date\", \"arrest_key\", \"latitude\", \"longitude\", )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce390a10-6d13-4b06-8468-f6cc0a14de96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subway_DF = subway_DF.join(arrest_DF, withinMetersUdf('GTFS Latitude', 'GTFS Longitude', 'latitude', 'longitude'), 'cross')\\\n",
    "    # .drop(F.col('latitude'))\\\n",
    "    # .drop(F.col('longitude'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e26f802-ec34-4ae7-9c41-f34c08667daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subway_DF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862f7b8c-773f-485b-9f82-dac20090e371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# arrest_count = subway_DF.groupBy(F.col('Stop Name')).count()\n",
    "# arrest_count = arrest_count.dropDuplicates(subset=[\"Stop Name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577651bf-7134-4bdc-9d78-2eeccc680e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# arrest_count.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09c0c78-12dc-422b-a189-76b579506748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# arrest_count.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94f9d6a-c5bc-4c2b-b150-f69055226a78",
   "metadata": {},
   "source": [
    "Building the smaller arrest dataset (10 rows) and trying to join with the subway data using the haversine function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "209d1f21-ef7c-42e4-86fc-5b80659d33f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lil_arrest_DF = lil_arrest_rdd.toDF(\":@computed_region_92fq_4b7q\", \":@computed_region_efsh_h5xi\", \":@computed_region_f5dn_yrer\", \":@computed_region_sbqj_enih\", \":@computed_region_yeji_bk3q\", \"age_group\", \"arrest_boro\", \"arrest_date\", \"arrest_key\", \"arrest_precinct\", \"jurisdiction_code\", \"ky_cd\", \"latitude\", \"law_cat_cd\", \"law_code\", \"lon_lat\", \"longitude\", \"ofns_desc\", \"pd_cd\", \"pd_desc\", \"perp_race\", \"perp_sex\", \"x_coord_cd\", \"y_coord_cd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "35367b0b-8769-4476-a461-0dcafedcbf69",
   "metadata": {},
   "outputs": [],
   "source": [
    "lil_arrest_DF = lil_arrest_DF.select(\"arrest_boro\",\"arrest_date\", \"arrest_key\", \"latitude\", \"longitude\", ).filter(F.col('latitude').isNotNull() & F.col('longitude').isNotNull()).withColumn(\"longitude\", F.col(\"longitude\").cast(\"double\")).withColumn(\"latitude\", F.col(\"latitude\").cast(\"double\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "72d5ae1e-11b0-4ebc-99f1-7bc311c83cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+----------+------------------+------------------+\n",
      "|arrest_boro|         arrest_date|arrest_key|          latitude|         longitude|\n",
      "+-----------+--------------------+----------+------------------+------------------+\n",
      "|          M|2021-11-22T00:00:...| 236791704|40.799008797000056|-73.95240854099995|\n",
      "|          B|2021-12-04T00:00:...| 237354740|40.816391847000034|-73.89529641399997|\n",
      "|          Q|2021-11-09T00:00:...| 236081433| 40.67970040800003|-73.77604736799998|\n",
      "|          M|2019-01-26T00:00:...| 192799737|40.800694331000045|-73.94110928599997|\n",
      "|          M|2019-02-06T00:00:...| 193260691| 40.75783900300007|-73.99121211099998|\n",
      "|          Q|2021-12-03T00:00:...| 237291769| 40.77205649600006|-73.87622400099998|\n",
      "|          B|2021-11-10T00:00:...| 236106641|40.804012949000025|-73.87833183299993|\n",
      "|          Q|2021-12-28T00:00:...| 238383628| 40.69166001700007|-73.77919852099996|\n",
      "|          K|2016-01-06T00:00:...| 149117452|40.648650085000035|-73.95033556299995|\n",
      "+-----------+--------------------+----------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lil_arrest_DF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a411b304-f06c-40d7-a43e-7e4b67bd183b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- arrest_boro: string (nullable = true)\n",
      " |-- arrest_date: string (nullable = true)\n",
      " |-- arrest_key: string (nullable = true)\n",
      " |-- latitude: double (nullable = true)\n",
      " |-- longitude: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lil_arrest_DF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "50cf9c26-bc9c-4319-8405-de6180cb5444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+----------+------------------+------------------+\n",
      "|arrest_boro|         arrest_date|arrest_key|          latitude|         longitude|\n",
      "+-----------+--------------------+----------+------------------+------------------+\n",
      "|          M|2021-11-22T00:00:...| 236791704|40.799008797000056|-73.95240854099995|\n",
      "|          B|2021-12-04T00:00:...| 237354740|40.816391847000034|-73.89529641399997|\n",
      "|          Q|2021-11-09T00:00:...| 236081433| 40.67970040800003|-73.77604736799998|\n",
      "|          M|2019-01-26T00:00:...| 192799737|40.800694331000045|-73.94110928599997|\n",
      "|          M|2019-02-06T00:00:...| 193260691| 40.75783900300007|-73.99121211099998|\n",
      "|          Q|2021-12-03T00:00:...| 237291769| 40.77205649600006|-73.87622400099998|\n",
      "|          B|2021-11-10T00:00:...| 236106641|40.804012949000025|-73.87833183299993|\n",
      "|          Q|2021-12-28T00:00:...| 238383628| 40.69166001700007|-73.77919852099996|\n",
      "|          K|2016-01-06T00:00:...| 149117452|40.648650085000035|-73.95033556299995|\n",
      "+-----------+--------------------+----------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lil_arrest_DF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463ac3fa-b9b5-4202-8524-71253bfbf131",
   "metadata": {},
   "source": [
    "Joining the subway dataframe to the smaller arrest data set unsuccessfully. I tried this with just the strings for the column names and with the F.col() structure but didn't have any success either way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a52d7306-8b04-4bb4-8c4b-4810efb10063",
   "metadata": {},
   "outputs": [],
   "source": [
    "subway_arrest_DF = subway_DF.join(lil_arrest_DF, withinMetersUdf(F.col('GTFS Latitude'), F.col('GTFS Longitude'), F.col('latitude'), F.col('longitude')), 'cross')\\\n",
    "    .drop(F.col('latitude'))\\\n",
    "    .drop(F.col('longitude'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536aa047-7a35-47df-bfc5-8da24caa1bac",
   "metadata": {},
   "source": [
    "The error occurs when trying to execute the pipeline graph with the show() below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3427eeaa-d965-4265-81d1-b27ea3542217",
   "metadata": {},
   "outputs": [],
   "source": [
    "subway_arrest_DF = subway_arrest_DF.na.drop(subset=[\"Stop Name\"])\n",
    "lil_arrest_count = subway_arrest_DF.groupBy(F.col('Stop Name')).count()\n",
    "lil_arrest_count.printSchema()\n",
    "lil_arrest_count.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8587f080-b19d-465d-b3df-a9ce6726989e",
   "metadata": {},
   "source": [
    "Testing the haversine function locally and it works so it seems like there's an issue passing the columns? I checked the hw2 submission and it seems fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cdcc1c11-aa59-45ca-92af-e8d0480ab715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'float'> <class 'float'>\n",
      "40.799008797000056 -73.95240854099995\n",
      "<class 'float'> <class 'float'>\n",
      "40.816391847000034 -73.89529641399997\n",
      "5180.8801108369735\n"
     ]
    }
   ],
   "source": [
    "distance = withinMeters(40.799008797000056, -73.95240854099995, 40.816391847000034, -73.89529641399997)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9f6f94-b2ea-4851-be60-f56ced80a652",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
